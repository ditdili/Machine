{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Example of a Neural Network with Tensorflow and Keras\n",
    "\n",
    "#### Tensorflow and Keras\n",
    "\n",
    "TensorFlow was developed at Google to use internally for machine learning tasks, and applied to the applications like speech recognition, Search, Gmail, etc. It was made public in 2015 as an open source application. The library is in C++, used with Python API. TensorFlow can be used for various problems like image recognition, language processing, implementation in self-driving cars, etc. There are various alternatives available to TensorFlow such as Theano, and Torch.\n",
    "\n",
    "We are going to use Keras in this notebook, with Tensorflow as a backend engine. Keras is a high-level wrapper, that can be used both with TensorFlow and Theano, which simplifies common operations. The code is similar to scikit-learn, making it easier to get used to it, while in the background TensorFlow or Theano is used for processing.\n",
    "\n",
    "#### The data\n",
    "\n",
    "Let's start by importing MNIST database (a subset of a larger set by National Institute of Standards and Technology). This is a classic dataset containing 60000 training images, 10000 test images, and correspoding training and test labels. The images are handwritten digits, in the shape of 28 x 28 pixels, and divided into 10 categories (from 0 to 9).\n",
    "\n",
    "#### The versions\n",
    "\n",
    "In this example I am using Keras v.2.1.4 and TensorFlow v.1.5.0 with GPU (using NVIDIA CUDA). Running examples on a GPU can speed up the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras: 2.1.4\n",
      "TensorFlow: 1.5.0\n"
     ]
    }
   ],
   "source": [
    "# To avoid warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing keras and tensorflow, and printing the versions\n",
    "import keras\n",
    "print('Keras: {}'.format(keras.__version__))\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TensorFlow: {}'.format(tf.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images shape: (60000, 28, 28)\n",
      "Training labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Importing MNIST data set\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Assigning the data from the data set\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "print('Training images shape: {}'.format(X_train.shape))\n",
    "print('Training labels shape: {}'.format(y_train.shape))\n",
    "print('Test images shape: {}'.format(X_test.shape))\n",
    "print('Test labels shape: {}'.format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data is in the shape of 28 x 28 pixels. Let's look at the first ten labels in the data set. Also we are going to visualize the first 10 digits by plotting the pixels information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First 10 labels\n",
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib library for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkMAAABICAYAAAD1YfFxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMcaYtGaTIWOMMcakNZsMGWOMMSat/R9pBekWJUCvagAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ac9dbd76d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Defining the figure for plotting, using 'xticks':[] and 'yticks':[]\n",
    "# to avoid the ticks on axes\n",
    "fig, axes = plt.subplots(1, 10, figsize=(10, 1),\n",
    "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
    "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
    "\n",
    "# Looping through the images and their corresponding labels\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(X_train[i], cmap='binary')\n",
    "    ax.text(0.05, 0.05, str(y_train[i]), transform=ax.transAxes, color='orangered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network with Keras and Tensorflow\n",
    "\n",
    "Models are defined as a sequence of layers. Sequential is imported from keras.models library, and a Sequential model is created.\n",
    "\n",
    "The network below consists of a sequence of two Dense layers. These layers are fully connected. We are using 'relu' rectifier activation function on the first layer (more on the relu on [Medium](https://towardsdatascience.com/activation-functions-neural-networks-1cbd9f8d91d6)). We are using 'softmax' as an activation function in the second layer, which will return an array of 10 probability scores, to define which class does the current digit belongs to.\n",
    "\n",
    "We will flatten the 28 x 28 pixels image to an input vector of a shape 784 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Sequential and Dense from keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Creating the model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Dense(784, activation='relu', input_shape=(28 * 28,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the model defined, it is time to compile it. Under the covers TensorFlow is used for compiling. We need to specify additional properties required for the neural network. \n",
    "\n",
    "* __A loss function__: measures the performance of a model, comparing y_pred to actual y. We will be using 'categorical_crossentropy' as the loss function for our model. 'categorical_crossentropy' reguires the target to be in a categorical format. In our case we have 10 categories, so the target should be in a format of 10-dimensional vector, all 0s except 1 for the actual index correspondoing to the class. [List of Loss functions](https://keras.io/losses/) at keras website.\n",
    "\n",
    "* __An optimizer__: searches through different weights for the network, and determines how the model will be updated based on the loss function. We will be implementing Adam optimizer. Adam optimizer is an extension to stochastic gradient descent. [List of Optimizers](https://keras.io/optimizers/) at keras website. More on Adam at [machinelearningmastery](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).\n",
    "\n",
    "* __Metrics__: is a function to judge the performance of the model. In this case we will collect and report the classification accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to preprocessed before applying the model to it. First we reshape 28 x 28 pixels into a vector of a shape 784. Then we are normalizing the scale from 0-255 to the range 0-1 by dividing the values by 255. Also we are converting the labels to categorical format. After the data is converted, we will print the first row in the training data to demonstrate converted label into categorical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the data\n",
    "X_train = X_train.reshape((X_train.shape[0], 28 * 28))\n",
    "X_test = X_test.reshape((X_test.shape[0], 28 * 28))\n",
    "\n",
    "# Converting the data to float32 type, and normalizing\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# Importing to_categorical to convert the label\n",
    "from keras.utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying first row of training label, corresponding to 5\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the above steps are taken, we can fit the training data and evaluate the model on the test data. This model is fit over 5 epochs (the amount of iterations over the data set), and the batch size of 150 (the total number of training samples present in a single batch)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 63us/step - loss: 0.2663 - acc: 0.9234\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.1019 - acc: 0.9704\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0655 - acc: 0.9805\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 38us/step - loss: 0.0463 - acc: 0.9863\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 40us/step - loss: 0.0325 - acc: 0.9904\n",
      "10000/10000 [==============================] - 1s 69us/step\n",
      "\n",
      "Model acc: 0.981\n"
     ]
    }
   ],
   "source": [
    "# Fitting the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=150)\n",
    "\n",
    "# Evaluating the model on the test set\n",
    "score = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Printing the accuracy score of the model over the test set\n",
    "print('\\nModel {}: {}'.format(model.metrics_names[1], score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model accuracy on the test data turns out to be about 98%. There is slight discprepancy between the training acccuracy and test accuracy due to some overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
